{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset -f\n",
    "#importing libraries\n",
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "#specifying data directory, current folder of this file joined with the folder containing the data\n",
    "DATA_FOLDER = os.path.join(Path.cwd(), \"cifar-10-batches-py/\")\n",
    "\n",
    "#gets filenames\n",
    "batch_names = sorted(glob.glob(f\"{DATA_FOLDER}/data*\"))\n",
    "test_names = os.path.join(DATA_FOLDER, \"test_batch\")\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, \"rb\") as f:\n",
    "        dict = pickle.load(f, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "#unpickles and divides the cifar batches into data and labels as a list of dictionaries,\n",
    "#also reshapes the 1000*3072 (n_pictures*color_channels) arrays into 3*32*32(n_channels, width, height)\n",
    "def read_data_label_set(filepaths):\n",
    "    \n",
    "    if isinstance(filepaths, list):\n",
    "    \n",
    "        li=[]\n",
    "        for file in filepaths:\n",
    "            unpacked = unpickle(file)\n",
    "            data = torch.FloatTensor(list(map(lambda x : np.reshape(x, (3, 32, 32)), unpacked[b'data'])))\n",
    "            labels = torch.tensor(unpacked[b'labels'])\n",
    "            li.append({\"data\":data, \"labels\":labels})\n",
    "        return li\n",
    "    else:\n",
    "        unpacked = unpickle(filepaths)\n",
    "        data = torch.FloatTensor(list(map(lambda x : np.reshape(x, (3, 32, 32)), unpacked[b'data'])))\n",
    "        labels = torch.tensor(unpacked[b'labels'])\n",
    "        dic = {\"data\":data, \"labels\":labels}\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes mean and std for the normalization\n",
    "unnorm_batches = read_data_label_set(batch_names)\n",
    "#concatenates 3 channels of all the batches\n",
    "concatChan = torch.cat([unnorm_batches[i][\"data\"] for i in range(len(unnorm_batches))]).permute(1,2,3,0).reshape(3,-1)\n",
    "#computes mean and st_dev\n",
    "mean = concatChan.mean(dim=1)/255\n",
    "st_dev = concatChan.std(dim=1)/255\n",
    "#Transformations for the dataset, that turn it into a tensor and normalize\n",
    "transf = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean = mean, std = st_dev)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset class for cifar10 to put into a dataloader later\n",
    "class Cif10Set(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        dataSetDict_List = read_data_label_set(data_path)\n",
    "        if isinstance(dataSetDict_List, list):\n",
    "            self.data = np.concatenate([dataSetDict_List[i][\"data\"] for i in range(len(dataSetDict_List))])/255\n",
    "            self.label = np.concatenate([dataSetDict_List[i][\"labels\"] for i in range(len(dataSetDict_List))])\n",
    "            self.length = self.data.shape[0]\n",
    "            self.transform = transform\n",
    "        else: \n",
    "            self.data =  dataSetDict_List[\"data\"]/255\n",
    "            self.label = dataSetDict_List[\"labels\"]\n",
    "            self.length = self.data.shape[0]\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            if not torch.is_tensor(self.data):\n",
    "                return self.transform(torch.from_numpy(self.data[index])), self.label[index]\n",
    "            else:\n",
    "                return self.transform(self.data[index]), self.label[index]\n",
    "        else:\n",
    "            return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sets datasets for training and testing\n",
    "#Training dataset\n",
    "train_set = Cif10Set(batch_names, transform = transf)\n",
    "#Testing dataset\n",
    "test_set = Cif10Set(test_names, transform = transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets dataloaders for training and testing\n",
    "#Training dataloader\n",
    "train_load = DataLoader(train_set, shuffle=True, batch_size=100)\n",
    "#Test dataloader\n",
    "test_load = DataLoader(test_set, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a convolutional network class\n",
    "class ConvNet(nn.Module):\n",
    "    # conv reduction: (W-F+2P)/S +1\n",
    "    # W:input, F:filter, P:padding, S:stride\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            # 3*32*32\n",
    "            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3,\n",
    "                      padding=1, stride=1),  # ->128*32*32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # ->128*16*16\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 128*16*16\n",
    "            nn.Conv2d(in_channels=128, out_channels=512,\n",
    "                      kernel_size=3, padding=1, stride=1),  # ->512*16*16\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # ->512*8*8\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # ->512*8*8\n",
    "            nn.Conv2d(in_channels=512, out_channels=512,\n",
    "                      kernel_size=3, padding=1, stride=1),  # ->512*8*8\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # ->512*4*4\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # ->512*4*4\n",
    "            nn.Conv2d(in_channels=512, out_channels=512,\n",
    "                      kernel_size=3, padding=1, stride=1),  # ->512*4*4\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # ->512*2*2\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # ->512*2*2\n",
    "            nn.Conv2d(in_channels=512, out_channels=512,\n",
    "                      kernel_size=3, padding=1, stride=1),  # ->512*2*2\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # ->512*1*1\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Flatten\n",
    "            nn.Flatten(),  # ->512\n",
    "            nn.Linear(512, 10)  # ->10\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.network(data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes model\n",
    "model = ConvNet()\n",
    "print(model)\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(sum(numel_list), numel_list)\n",
    "\n",
    "# defines optimizer, loss function and the hyperparameters\n",
    "# hyperparameters\n",
    "learning_rate = 0.009\n",
    "epochs = 3\n",
    "loss_meas = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model\n",
    "check_poi = torch.load(\"./cifar_m_FromCell.pt\")\n",
    "model = ConvNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model.load_state_dict(check_poi[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(check_poi[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO improve outputs, shuffle, add dropout, add batch norm, add augment, add cross validation\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # iterates over batches\n",
    "    for batch_num, (imageData, labels) in enumerate(train_load):\n",
    "        # forward pass        \n",
    "\n",
    "        #model_out = model(batch[\"data\"])\n",
    "        model_out = model(imageData)\n",
    "\n",
    "        #loss = loss_meas(model_out, batch[\"labels\"])\n",
    "        loss = loss_meas(model_out, labels)\n",
    "\n",
    "        #optimization and backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        #print statistics\n",
    "        if batch_num*100 % 2000 == 0:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.4f' %(epoch + 1, batch_num*100, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\"\"\"\n",
    "    #saves a model every epoch, uncommented because space UgU            \n",
    "    savename = \"cifar_m\"+str(epoch)+\".pt\"\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss,\n",
    "            }, savename)         \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save current model manually\n",
    "savename = \"cifar_m_FromCell.pt\"\n",
    "torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': running_loss,\n",
    "        }, savename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation of the model\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, batch in enumerate(test_load):\n",
    "        images, labels = batch\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "        total += labels.size()[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print(\"Accuracy: \", (correct/total)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A cell to test taken pictures in the same folder as this file\n",
    "imgNames = glob.glob(os.path.join(Path.cwd(), \"*.png\"))\n",
    "img = [cv.imread(file) for file in imgNames]\n",
    "print(glob.glob(os.path.join(Path.cwd(), \"*.png\")))\n",
    "resized = torch.tensor([cv.resize(img[i], dsize=(32, 32), interpolation=cv.INTER_CUBIC) for i in range(len(img))])  \n",
    "transposed = torch.stack([torch.transpose(resized[i], 2, 0) for i in range(len(resized))])\n",
    "inp = transposed.float()/255\n",
    "\n",
    "outputs = model(inp)\n",
    "print(outputs)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "print([img.split(\"/\")[-1] for img in imgNames])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows image at index\n",
    "img = unnorm_batches[0][\"data\"][0]/255\n",
    "plt.imshow(img.permute((1, 2, 0)))\n",
    "\n",
    "isinstance(train_set.data, list)\n",
    "torch.is_tensor(test_set.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
